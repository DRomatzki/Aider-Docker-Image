{
    "ollama/DeepSeekCoderV2": {
        "max_tokens": 128000,
        "max_input_tokens": 64000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 0.00000014,
        "output_cost_per_token": 0.00000028,
        "litellm_provider": "ollama",
        "mode": "instruct"
    },
    "Llama3": {
        "max_tokens": 64000,
        "max_input_tokens": 48000,
        "max_output_tokens": 12000,
        "input_cost_per_token": 0.00000014,
        "output_cost_per_token": 0.00000028,
        "litellm_provider": "ollama",
        "mode": "instruct"
    },
    "Gwen2": {
        "max_tokens": 8192,
        "max_input_tokens": 6000,
        "max_output_tokens": 2000,
        "input_cost_per_token": 0.00000014,
        "output_cost_per_token": 0.00000028,
        "litellm_provider": "ollama",
        "mode": "instruct"
    },
    "Gemma2": {
        "max_tokens": 64000,
        "max_input_tokens": 48000,
        "max_output_tokens": 12000,
        "input_cost_per_token": 0.00000014,
        "output_cost_per_token": 0.00000028,
        "litellm_provider": "ollama",
        "mode": "instruct"
    }
}

